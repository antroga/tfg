---
title: "Aprendizaje supervisado: Árbol de decisión"
output: html_notebook
---

En este apartado se lleva a cabo un estudio de tipo supervisado con el algoritmo de árbol de decisión XXX

En primer lugar se instalan los paquetes y se cargan las librerías necesarias.
```{r}
#install.packages("rpart")
#install.packages("rpart.plot")
library(rpart)
library(rpart.plot)
library(dplyr)
library(caret)
```
Cargo el dataframe
```{r}
grafodf <- read.table("./dataframe.txt", header = TRUE, sep = ",")
print(grafodf)
```
Cambio los nombres de las columnas para facilitar la aplicación de los algoritmos.
```{r}
colnames(grafodf) <- c("x", "NODOS", "X1","X2", "X3", "X4", "Y1", "Y2" )
```

Divido el conjunto de datos en test (75%) y train (25%).
```{r}
set.seed(101)  
sample <- sample.int(n = nrow(grafodf), size = floor(.75*nrow(grafodf)), replace = F)
train <- grafodf[sample, ]
test  <- grafodf[-sample, ]
```
Creamos dos conjuntos, uno para cada etiqueta.
(dim, class, de los conjuntos de test y train)
```{r}
trainY1 <- train[, 2:7]
testY1 <- test[, 2:7]
df1 <- grafodf[, 2:7]
trainY2 <- select(train, 3,4,5,6,8) 
testY2 <- select(test, 3,4,5,6,8) 
df2 <- select(grafodf, 3,4,5,6,8) 
```
Construyo el modelo.
```{r}
fit1 <- rpart(Y1~., data = trainY1, method = 'class')
rpart.plot(fit1, extra = 106)

fit2 <- rpart(Y2~., data = trainY2, method = 'class')
rpart.plot(fit2, extra = 106)
```
Predecimos:
```{r}
predict_Y1 <-predict(fit1, testY1, type = 'class')
predict_Y2 <-predict(fit2, testY2, type = 'class')
```
Evaluamos los resultados de las predicciones con una matriz de confusión.
```{r}
table1 <- table(testY1$Y1, predict_Y1)
table1
table2 <- table(testY2$Y2, predict_Y2)
table2
```
Y con la métrica de precisión (accuracy).
```{r}
accuracy1 <- sum(diag(table1)) / sum(table1)
print(paste('Accuracy for test Y1:', accuracy1))
accuracy2 <- sum(diag(table2)) / sum(table1)
print(paste('Accuracy for test Y2:', accuracy2))
```

Ahora probamos el entrenamiento del modelo aplicando la validación cruzada.
Aplicamos k-CV, con k = 5.
```{r}
folds1 <- createFolds(trainY1$Y1, k = 5)
folds2 <- createFolds(trainY2$Y2, k = 5)
```
Entreno el modelo y evalúo los resultados. 
```{r}
cvDecisionTree1 <- lapply(folds1, function(x){
  training_fold <- trainY1[-x, ]
  test_fold <- trainY1[x, ]
  clasificador <- rpart(Y1 ~ ., data = training_fold, method = 'class')
  y_pred <- predict(clasificador, test_fold, type = 'class')
  cm <- table(test_fold$Y1, y_pred)
  precision <- (cm[1,1] + cm[2,2]) / (cm[1,1] + cm[2,2] +cm[1,2] + cm[2,1])
  print(cm)
  print(paste('Accuracy for test Y1:', precision))
})

cvDecisionTree2 <- lapply(folds2, function(x){
  training_fold <- trainY2[-x, ]
  test_fold <- trainY2[x, ]
  clasificador <- rpart(Y2 ~ ., data = training_fold, method = 'class')
  y_pred <- predict(clasificador, test_fold, type = 'class')
  cm <- table(test_fold$Y2, y_pred)
  precision <- (cm[1,1] + cm[2,2]) / (cm[1,1] + cm[2,2] +cm[1,2] + cm[2,1])
  print(cm)
  print(paste('Accuracy for test Y2:', precision))
})
```

Probamos el modelo para el primer conjunto de test.
```{r}

```
