---
title: "Aprendizaje supervisado: Xgboost"
output: html_notebook
---

En este apartado se lleva a cabo un estudio de tipo supervisado con el algoritmo de Xgboost.

En primer lugar se instalan los paquetes y se cargan las librerías necesarias.
```{r}
#install.packages("xgboost")
library(xgboost)
library(dplyr)
packageurl <- "http://cran.r-project.org/src/contrib/Archive/ggplot2/ggplot2_0.9.1.tar.gz"
#install.packages(packageurl, repos=NULL, type="source")
library(caret)
```
Cargo el dataframe
```{r}
grafodf <- read.table("./grafodf.txt", header = TRUE, sep = ",")
```
Cambio los nombres de las columnas para facilitar la aplicación de los algoritmos.
```{r}
colnames(grafodf) <- c("ID", "NODOS", "X0","X1", "X2", "X3", "Y1", "Y2" )
grafodf
```
Creo dos conjuntos, uno para cada etiqueta.
```{r}
df1 <- grafodf[, 3:7]
df2 <- select(grafodf,3,4,5,6, 8) 
df2$Y2 <- as.numeric(df2$Y2)
```
Divido el conjunto de datos en test (75%) y train (25%), para ambas etiquetas.
- Y1.
```{r}
set.seed(3456)

trainIndex1 <- createDataPartition(df1$Y1, p = .75, 
                                  list = FALSE)
trainY1 <- df1[ trainIndex1,]
testY1  <- df1[-trainIndex1,]
```
Visualizamos los conjuntos.
El conjunto de train está formado por 133 ejemplos y el de test, por 44.
```{r}
summary(trainY1)
dim(trainY1)
summary(testY1)
dim(testY1)
```

- Y2.
```{r}
set.seed(1)
trainIndex2 <- createDataPartition(df2$Y2, p = .75, 
                                  list = FALSE)
trainY2 <- df2[ trainIndex2,]
testY2  <- df2[-trainIndex2,]
```
Visualizamos los conjuntos.
El conjunto de train está formado por 133 ejemplos y el de test, por 44.
```{r}
summary(trainY2)
dim(trainY2)
summary(testY2)
dim(testY2)
```

Genero los modelos con los datos por defecto.
```{r}
modelo1 <- xgboost(data = as.matrix(trainY1), label = trainY1$Y1, nround = 2, objective = "binary:logistic")

modelo2 <- xgboost(data =as.matrix(trainY2), label = trainY2$Y2, nround = 2, objective = "binary:logistic")
```
Observo las características de los modelos generados.
```{r}
summary(modelo1)
summary(modelo2)
```

Evalúo los resultados.
- Etiqueta Y1 (ser nodo aislado):
Como siempre, las métricas Accuracy y Kappa son 1. 
```{r}
pred1 <- predict(modelo1, newdata =as.matrix(testY1))
predicciones <- as.numeric(pred1 > 0.5)
confusionMatrix(table(predicciones, testY1$Y1))
```
- Etiqueta Y2 (estar en NGC):
La precisión es 1.
```{r}
pred2 <- predict(modelo2, newdata =as.matrix(testY2))
predicciones <- as.numeric(pred2 > 0.5)
confusionMatrix(table(predicciones, testY2$Y2))
```
Los modelos tienen un desempeño perfecto, aunque puede deberse a un sobre ajuste de los mismos.

Ahora se hace uso de validación cruzada, con la que se entrena y prueba varias veces el modelo, obteniéndose múltiples estimaciones de error. Si las estimaciones son similares, el modelo será bueno.
Se utiliza K-CV, con k =10.
```{r}
control_class <- trainControl(
  method = "cv",
  number = 10
)
```
También optimizamos los hiperparámetros del modelo, probando distintos valores y evaluándolos con validación cruzada. 
- Etiqueta Y1 (ser nodo aislado):
Se prueban 10 valores distintos del parámetro principal, cp.
```{r}
xgb_grid <- expand.grid(
  nrounds = c(1,2),
  eta = c(0.1,0.3, 0.5),
  max_depth = c(2,3),
  gamma = c(0,1),
  colsample_bytree= c(1,2), 
  min_child_weight=c(1,2),
  subsample=c(1,2)
)
modelo1 <- train (Y1 ~ ., trainY1,
                 tuneGrid = xgb_grid,
                 method="xgbTree", 
                 trControl=control_class)

print(modelo1)
```
Predecimos usando el modelo óptimo:
```{r}
pred1 <- predict(modelo1, testY1)
predicciones <- as.numeric(pred1 > 0.5)
confusionMatrix(table(predicciones, testY1$Y1))
```
La optimización parece mejorar el modelo.

- Etiqueta Y2 (estar en NCG):
```{r}
modelo2 <- train (Y2 ~ ., trainY2,
                 tuneGrid = xgb_grid,
                 method="xgbTree", 
                 trControl=control_class)
print(modelo2)
```
Predecimos usando el modelo óptimo:
Clasifica todo como la clase mayoritaria (0).
```{r}
pred2 <- predict(modelo2, testY2)
predicciones <- as.numeric(pred2 > 0.5)
predicciones
confusionMatrix(table(predicciones, testY2$Y2))
```
El modelo, que ya ofrecía unos resultados perfectos, no mejora al optimizar los hiperparámetros.