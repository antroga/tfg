---
title: "Aprendizaje supervisado: SVM"
output: html_notebook
---

En este apartado se lleva a cabo un estudio de tipo supervisado con el algoritmo SVM (Support Vector Machines) 

En primer lugar se instalan los paquetes y se cargan las librerías necesarias.
```{r}
#install.packages("e1071")
library(dplyr)
library(igraph)
library(readxl)
library(e1071)
```

Cargo el dataframe
```{r}
grafodf <- read.table("./dataframe.txt", header = TRUE, sep = ",")
print(grafodf)
```
Cambio los nombres de las columnas para facilitar la aplicación de los algoritmos.
```{r}
colnames(grafodf) <- c("x", "NODOS", "X1","X2", "X3", "X4", "Y1", "Y2" )
```
Estandarizo los valores, ya que de lo contrario los predictores de mayor magnitud eclipsarían a los de menor magnitud.
```{r}
grafodf$X1 <- scale(grafodataframe$X1)
grafodf$X2 <- scale(grafodataframe$X2)
grafodf$X3 <- scale(grafodataframe$X3)
grafodf$X4 <- scale(grafodataframe$X4)
grafodf
```

Divido el conjunto de datos en test (75%) y train (25%).
```{r}
set.seed(101)  
sample <- sample.int(n = nrow(grafodf), size = floor(.75*nrow(grafodf)), replace = F)
train <- grafodf[sample, ]
test  <- grafodf[-sample, ]
```
Para aplicar el algoritmo, es necesario que las variables de respuesta sean factores.
```{r}
train$Y1 <- as.factor(train$Y1)
train$Y2 <- as.factor(train$Y2)
test$Y1 <- as.factor(test$Y1)
test$Y2 <- as.factor(test$Y2)
grafodf$Y1 <- as.factor(grafodf$Y1)
grafodf$Y2 <- as.factor(grafodf$Y2)
```
Creamos dos conjuntos, uno para cada etiqueta.
```{r}
trainY1 <- train[, 2:7]
testY1 <- test[, 2:7]
df1 <- grafodf[, 2:7]
trainY2 <- select(train, 3,4,5,6,8) 
testY2 <- select(test, 3,4,5,6,8) 
df2 <- select(grafodf, 3,4,5,6,8) 
```

Construimos el modelo.
La semilla asegura la reproducibilidad de los cálculos.
```{r}
set.seed(10111)
modelo_svm1 <- svm(formula = Y1 ~ ., data = trainY1, kernel = "linear",
                  cost = 10, scale = FALSE)
modelo_svm2 <- svm(formula = Y2 ~ ., data = trainY2, kernel = "linear",
                  cost = 10, scale = FALSE)
```
Vemos las características del modelo. 
Hay un total de dos vectores, cada uno perteneciente a una clase.
```{r}
summary(modelo_svm1)
summary(modelo_svm2)
```
Índice de las observaciones que actúan como vector soporte
```{r}
modelo_svm1$index
modelo_svm2$index
```
Visualizamos los resultados para la predicción de la primera etiqueta (ser nodo aislado)
```{r}
# Predicciones
predicciones <- predict(object = modelo_svm1, testY1)
paste("Error de test:", 100*mean(testY1$Y1 != predicciones),"%")
```
Visualizamos los resultados para la predicción de la segunda etiqueta (estar en la lista TCGA)
```{r}
# Predicciones
predicciones <- predict(object = modelo_svm2, testY2)
paste("Error de test:", 100*mean(testY2$Y2 != predicciones),"%")
```
La función tune permite optimizar los hiperparámetros del modelo SVM.
Para la etiqueta 1:
```{r}
svm_cv1 <- tune("svm", Y1 ~ ., data = df1,
               kernel = 'linear',
               ranges = list(cost = c(0.001, 0.01, 0.1, 1, 5, 10, 20, 50, 100,
                                      150, 200)))

summary(svm_cv1)
```
Para la etiqueta 2:
```{r}
svm_cv2 <- tune("svm", Y2 ~ ., data = df2,
               kernel = 'linear',
               ranges = list(cost = c(0.001, 0.01, 0.1, 1, 5, 10, 20, 50, 100,
                                      150, 200)))

summary(svm_cv2)
```
No tiene sentido la clasificación.
Tenemos muy pocos datos para usar este tratamiento.
 

Aplicamos k-CV, con k = 5.
```{r}
folds1 <- createFolds(trainY1$Y1, k = 5)
folds2 <- createFolds(trainY2$Y2, k = 5)
```
Entreno el modelo y evalúo los resultados.
```{r}
cvKernelSVM <- lapply(folds1, function(x){
  training_fold <- trainY1[-x, ]
  test_fold <- trainY1[x, ]
  clasificador <- svm(Y1 ~ .,
                      data = training_fold, 
                      type = 'C-classification', 
                      kernel = 'linear')
  y_pred <- predict(clasificador, newdata = test_fold)
  cm <- table(test_fold$Y1, y_pred)
  precision <- (cm[1,1] + cm[2,2]) / (cm[1,1] + cm[2,2] +cm[1,2] + cm[2,1])
  print(cm)
  print(paste('Accuracy for test Y1:', precision))
})

cvKernelSVM <- lapply(folds2, function(x){
  training_fold <- trainY2[-x, ]
  test_fold <- trainY2[x, ]
  clasificador <- svm(Y2 ~ .,
                      data = training_fold, 
                      type = 'C-classification', 
                      kernel = 'linear')
  y_pred <- predict(clasificador, newdata = test_fold)
  cm <- table(test_fold$Y2, y_pred)
  precision <- (cm[1,1] + cm[2,2]) / (cm[1,1] + cm[2,2] +cm[1,2] + cm[2,1])
  print(cm)
  print(paste('Accuracy for test Y2:', precision))
})
```
