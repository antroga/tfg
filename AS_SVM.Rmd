---
title: "Aprendizaje supervisado: SVM"
output: html_notebook
---

En este apartado se lleva a cabo un estudio de tipo supervisado con el algoritmo SVM (Support Vector Machines) 

En primer lugar se instalan los paquetes y se cargan las librerías necesarias.
```{r}
#install.packages("e1071")
library(dplyr)
library(igraph)
library(readxl)
library(e1071)
library(caret)
```

Cargo el dataframe
```{r}
grafodf <- read.table("./grafodf.txt", header = TRUE, sep = ",")
```
Cambio los nombres de las columnas para facilitar la aplicación de los algoritmos.
```{r}
colnames(grafodf) <- c("ID","NODOS", "X1","X2", "X3", "X4", "Y1", "Y2" )
```
Para aplicar el algoritmo, es necesario que las variables de respuesta sean factores.
```{r}
grafodf$Y1 <- as.factor(grafodf$Y1)
grafodf$Y2 <- as.factor(grafodf$Y2)
```

Creo dos conjuntos, uno para cada etiqueta.
```{r}
df1 <- grafodf[, 3:7]
df2 <- select(grafodf,3,4,5,6, 8) 
```
- Y1.
```{r}
set.seed(3456)

trainIndex1 <- createDataPartition(df1$Y1, p = .75, 
                                  list = FALSE)
trainY1 <- df1[ trainIndex1,]
testY1  <- df1[-trainIndex1,]
```
Visualizamos los conjuntos.
El conjunto de train está formado por 133 ejemplos y el de test, por 44.
```{r}
summary(trainY1)
dim(trainY1)
summary(testY1)
dim(testY1)
```
- Y2.
```{r}
set.seed(1)
trainIndex2 <- createDataPartition(df2$Y2, p = .75, 
                                  list = FALSE)
trainY2 <- df2[ trainIndex2,]
testY2  <- df2[-trainIndex2,]
```
Visualizamos los conjuntos.
El conjunto de train está formado por 133 ejemplos y el de test, por 44.
```{r}
summary(trainY2)
dim(trainY2)
summary(testY2)
dim(testY2)
```

Construimos el modelo con los valores por defecto.
El estblecimiento de una semilla asegura la reproducibilidad de los cálculos.
```{r}
set.seed(10110)
modelo_svm1 <- svm(formula = Y1 ~ ., data = trainY1, kernel = "linear",
                   scale = FALSE)
modelo_svm2 <- svm(formula = Y2 ~ ., data = trainY2, kernel = "linear",
                  scale = FALSE)
```

Vemos las características de los modelos generados. 
Para la primera etiqueta, hay un total de 6 vectores.
Para la segunda etiqueta, 47.
```{r}
summary(modelo_svm1)
summary(modelo_svm2)
```
Índice de las observaciones que actúan como vector soporte
```{r}
modelo_svm1$index
modelo_svm2$index
```

- Y1 (ser nodo aislado).
Visualizamos los resultados para la predicción de la primera etiqueta.
Las métricas Accuracy y Kappa son 1. No hay errores.
```{r}
pred1 <- predict(modelo_svm1, testY1, type = 'class')
confusionMatrix(table(pred1, testY1$Y1))
```

- Y2 (estar en la lista NCG)
Visualizamos los resultados para la predicción de la segunda etiqueta.
La métrica Accuracy es o.8864. La métrica Kappa es 0, es decir, no mejoramos al modelo que lo clasifica todo como la clase dominante. 
```{r}
pred2 <- predict(modelo_svm2, testY2, type = 'class')
confusionMatrix(table(pred2, testY2$Y2))
```
Estos resultados han sido obtenidos tras un único proceso de entrenamiento y prueba, y usando los valores por defecto.
A continuación se llevará a cabo una optimización del algoritmo, probando distintos valores del parámetro cost y evaluando con kCV, validación cruzada con k = 10.
Como las predicciones de la etiqueta Y1 no pueden mejorar, no se tendrán en cuenta a partir de aquí.
```{r}
control_class <- trainControl(
  method = "cv",
  number = 10
)
```

Para la etiqueta Y2 (estar en NCG):
```{r}
costs = seq(1 , 100, by=10)
svm2<- train (Y2 ~ ., trainY2,
                 tuneGrid = expand.grid(cost = costs),
                 method="svmLinear2", 
                 trControl=control_class)
print(svm2)
```
Evalúo con el modelo óptimo.
```{r}
pred2 <- predict(svm2, testY2)
confusionMatrix(table(pred2, testY2$Y2))
```
El modelo no mejora, sigue clasificando todos los ejemplos en la clase dominante. Esto se debe a que las clases están muy desbalanceadas.