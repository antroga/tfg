---
title: "Aprendizaje supervisado: Xgboost"
output: html_notebook
---

En este apartado se lleva a cabo un estudio de tipo supervisado con el algoritmo de Xgboost.

En primer lugar se instalan los paquetes y se cargan las librerías necesarias.
```{r}
#install.packages("xgboost")
library(xgboost)
library(dplyr)
library(caret)
```
Cargo el dataframe
```{r}
grafodf <- read.table("./dataframe.txt", header = TRUE, sep = ",")
print(grafodf)
```
Cambio los nombres de las columnas para facilitar la aplicación de los algoritmos.
```{r}
colnames(grafodf) <- c("x", "NODOS", "X1","X2", "X3", "X4", "Y1", "Y2" )
```

Divido el conjunto de datos en test (75%) y train (25%).
```{r}
set.seed(101)  
sample <- sample.int(n = nrow(grafodf), size = floor(.75*nrow(grafodf)), replace = F)
train <- grafodf[sample, ]
test  <- grafodf[-sample, ]
```
Creamos dos conjuntos, uno para cada etiqueta.
```{r}
trainY1 <- train[, 2:7]
testY1 <- test[, 2:7]
df1 <- grafodf[, 2:7]
trainY2 <- select(train, 3,4,5,6,8) 
testY2 <- select(test, 3,4,5,6,8) 
df2 <- select(grafodf, 3,4,5,6,8) 
```
Los convierto en matrices, que es lo que usa este algoritmo como dato de entrada.
```{r}
mtrain1 <- as.matrix(trainY1[, -1])
mtest1 <- as.matrix(testY1[, -1])
mtrain2 <- as.matrix(trainY2[, -1])
mtest2 <- as.matrix(testY2[, -1])
```
Creo una función que evaluará la calidad de los modelos.
```{r}
evaluacion1 <- function(fit) {
    pred1 <- predict(fit, mtest1, type = 'class')
    predicciones <- as.numeric(pred1 > 0.5)
    table_mat <- table(testY1$Y1, predicciones)
    accuracy_Test <- sum(diag(table_mat)) / sum(table_mat)
    print(table_mat)
    print(paste('Accuracy para Y1:', accuracy_Test))
}

evaluacion2 <- function(fit) {
    pred2 <- predict(fit, mtest2, type = 'class')
    predicciones <- as.numeric(pred2 > 0.5)
    table_mat <- table(testY2$Y2, predicciones)
    accuracy_Test <- sum(diag(table_mat)) / sum(table_mat)
    print(table_mat)
    print(paste('Accuracy para Y2:', accuracy_Test))
}
```

Entreno los modelos
```{r}
modelo1 <- xgboost(data = mtrain1, label = trainY1$Y1, max.depth = 2,
               eta = 1, nthread = 2, nround = 2, objective = "binary:logistic")

modelo2 <- xgboost(data = mtrain2, label = trainY2$Y2, max.depth = 2,
               eta = 1, nthread = 2, nround = 2, objective = "binary:logistic")
```
Observo las características de los modelos generados.
```{r}
summary(modelo1)
summary(modelo2)
```

Evalúo los resultados.
- Etiqueta Y1 (ser nodo aislado):
```{r}
evaluacion1(modelo1)
```
- Etiqueta Y2 (estar en NGC):
```{r}
evaluacion2(modelo2)
```

Los modelos tienen un desempeño perfecto. ¿Por qué?
```{r}

```

