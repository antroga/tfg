---
title: "ANEXO 2. Aprendizaje no supervisado sobre la matriz"
output: html_notebook
---

En este notebook se lleva a cabo un análisis no supervisado para dividir en clústeres o subgrafos la red de oncogenes que estamos estudiando.
El clustering se hace sobre la matriz de adyacencia del grafo. 
Se hace uso de dos tipos de clustering: jerárquico y con kmeans.

En primer lugar, cargamos las librerías necesarias.
```{r}
#install.packages("factoextra")
library(igraph)
library(readxl)
library(factoextra)
library(dplyr)
```
Se carga el grafo
```{r}
#Cargo datos
aristas <- read_excel("./Dataset1.xlsx", 
                    sheet = "WeigthedNetwork")
nodos <- read_excel("./Dataset1.xlsx", 
                    sheet = "NetworkNodes")
#Construyo el grafo
grafo_origen <- 
  graph_from_data_frame(d = aristas, vertices = nodos,  directed=F)

#Podo cogiendo como umbral 0.4
grafo <- delete_edges(grafo_origen, E(grafo_origen)[PESO<0.4])
```

Generamos la matriz de adyacencia.
```{r}
matgraf <- get.adjacency(grafo, attr="PESO", sparse=F)
```

ALGORITMO K-MEANS

En primer lugar, observamos el valor óptimo de k que resulta ser k=4.
```{r}
fnb<- fviz_nbclust(matgraf, kmeans, method = "silhouette")
fnb
```

Aplicamos el clustering con kmeans para k=4.
```{r}
km_grafo <- kmeans(matgraf, centers = 4, nstart = 20)

#visualización
plot(matgraf, col= km_grafo$cluster, main="k-means k=4")
```

Se observan las características del conjunto de datos.
```{r}
summary(km_grafo)
```

Estudiamos cada cluster por separado.
```{r}
km_clusteres <- km_grafo$cluster
kmclust <- data.frame(nodos, km_clusteres)

c1 <- filter(kmclust, kmclust$km_clusteres == 1)
c1
c2 <- filter(kmclust, kmclust$km_clusteres == 2)
c2
c3 <- filter(kmclust, kmclust$km_clusteres == 3)
c3
c4 <- filter(kmclust, kmclust$km_clusteres == 4)
c4
```

CLUSTERING JERÁRQUICO

Observamos el numero óptimo de clusters.

```{r}
fnv<- fviz_nbclust(matgraf, hcut, method = "silhouette")
fnv
```

Obtengo la matriz de distancias y el dendograma.

```{r}

#1- matriz de distancias con dist
matriz_dist <- dist(matgraf)
#2- hclust para construir dendograma
hclust_aux <- hclust(matriz_dist, method = "average")
plot(hclust_aux)
```
Corto el dendograma para k = 2
```{r}
#3- cortar el dendograma y obtener clusters con cutree
grupos1 <- cutree(hclust_aux, k=2)

#represento los resultados
plot(matgraf, col=grupos1, main = "Clustering jerárquico k=2")
```

Se observan las características de los datos generados.
```{r}
summary(grupos1)
```

Se estudian los clusteres por separado.
```{r}
hjclust <- data.frame(nodos, grupos1) 

c1 <- filter(hjclust, hjclust$grupos1 == 1)
c1
c2 <- filter(hjclust, hjclust$grupos1 == 2)
c2
```
